#+TITLE: An Update on Statistics Target
#+DATE: 2019-12-01T10:30:00+01:00
#+TAGS: ["Postgres"]
#+DRAFT: false

[[/posts/analyze-extreme-distributions-in-postgresql/][Earlier I analyzed]] the influence of the statistics target on the result of
sampling for extreme distributions.  The representatin of extreme rare values in
the [[https://www.postgresql.org/docs/current/view-pg-stats.html ][most common
values]] required a
drastic increase of the sample size.

In PostgreSQL 9.6 the situation improved and some [[https://www.postgresql.org/docs/release/9.6.0/][improvements for =analyze=]]
were released.  More work was done on this issue to improve the [[https://www.postgresql.org/docs/release/11.0/][selection of
most common values]] which was released in PostgreSQL 11.

I was curious how the situation has changed.  Which values for the =statistics
target= should I choose in a similar situation?  So I repeated the analysis with
a newer version of Postgres.  Below you find the results for PostgeSQL 11.2 (10
Mio rows, 10 samples for =analyze=).

[[file:/extreme/Postgres11.2.png]]

Now the graphs are monotonic.  What an achievement!
